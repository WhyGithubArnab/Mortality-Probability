{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import csv\n",
    "\n",
    "'''For educational purpose only. 11.csv will be read from the current folder of this directory and uploaded \n",
    "   to the remote datbase only once (WORM). I have already uploaded the data to the remote database and have\n",
    "   commented out the code that actually calls the method to load the data from the datafram to remote table\n",
    "   You will need the following packages:\n",
    "   pandas\n",
    "   sqlalchemy\n",
    "   \n",
    "   To install sqlalchemy use either of the following commands:\n",
    "   conda install -c anaconda sqlalchemy \n",
    "   or\n",
    "   pip install SQLAlchemy\n",
    "   '''\n",
    "\n",
    "infile = '11.csv'\n",
    "db = 'datascience'\n",
    "db_tbl_name = 'raw_data'\n",
    "\n",
    "'''\n",
    "    Load a csv file into a dataframe; if csv does not have headers, use the headers arg to create a list of headers; \n",
    "    rename unnamed columns to conform to mysql column requirements.\n",
    "    Our csv file has a header row and hence the column names are read from the same.\n",
    "'''\n",
    "def csv_to_df(infile, headers = []):\n",
    "    if len(headers) == 0:\n",
    "        df = pd.read_csv(infile)\n",
    "    else:\n",
    "        df = pd.read_csv(infile, header = None)\n",
    "        df.columns = headers\n",
    "    for r in range(10):\n",
    "        try:\n",
    "            df.rename( columns={'Unnamed: {0}'.format(r):'Unnamed{0}'.format(r)},    inplace=True )\n",
    "        except:\n",
    "            pass\n",
    "        df.head()\n",
    "    return df\n",
    "\n",
    "'''\n",
    "Create a mapping of df dtypes to mysql data types (not perfect, but close enough)\n",
    "'''\n",
    "def dtype_mapping():\n",
    "    return {'object' : 'TEXT',\n",
    "        'int64' : 'INT',\n",
    "        'float64' : 'FLOAT',\n",
    "        'datetime64' : 'DATETIME',\n",
    "        'bool' : 'TINYINT',\n",
    "        'category' : 'TEXT',\n",
    "        'timedelta[ns]' : 'TEXT'}\n",
    "'''\n",
    "Create a sqlalchemy engine. We are connecting to a remote database hosted for our school operations at nextideacademy.org\n",
    "'''\n",
    "def mysql_engine(user = 'datascience', password = '76BW9uULcZcYl9SG', host = 'nextideacademy.org', port = '3306', database = 'datascience'):\n",
    "    engine = create_engine(\"mysql://{0}:{1}@{2}:{3}/{4}?charset=utf8\".format(user, password, host, port, database))\n",
    "    return engine\n",
    "\n",
    "'''\n",
    "Create a mysql connection from sqlalchemy engine\n",
    "'''\n",
    "def mysql_conn(engine):\n",
    "    conn = engine.raw_connection()\n",
    "    return conn\n",
    "'''\n",
    "Create sql input for table names and types\n",
    "'''\n",
    "def gen_tbl_cols_sql(df):\n",
    "    dmap = dtype_mapping()\n",
    "    sql = \"pi_db_uid INT AUTO_INCREMENT PRIMARY KEY\"\n",
    "    df1 = df.rename(columns = {\"\" : \"nocolname\"})\n",
    "    hdrs = df1.dtypes.index\n",
    "    hdrs_list = [(hdr, str(df1[hdr].dtype)) for hdr in hdrs]\n",
    "    for i, hl in enumerate(hdrs_list):\n",
    "        sql += \" ,{0} {1}\".format(hl[0], dmap[hl[1]])\n",
    "    return sql\n",
    "\n",
    "'''\n",
    "Create a mysql table from a df\n",
    "This takes the header information from the csv file and creates the table based on the header row\n",
    "'''\n",
    "def create_mysql_tbl_schema(df, conn, db, tbl_name):\n",
    "    tbl_cols_sql = gen_tbl_cols_sql(df)\n",
    "    sql = \"USE {0}; CREATE TABLE IF NOT EXISTS  {1} ({2})\".format(db, tbl_name, tbl_cols_sql)\n",
    "    print (\"Create table SQL:\" + sql)\n",
    "    cur = conn.cursor()\n",
    "    try:\n",
    "        print(\"Creating Table\")\n",
    "        cur.execute(sql)\n",
    "        print(\"End of table creation\")\n",
    "        cur.close()\n",
    "        conn.commit()\n",
    "    except Exception as inst:\n",
    "        print(type(inst))    # the exception instance\n",
    "        print(inst.args)     # arguments stored in .args\n",
    "        print(inst)  \n",
    "        pass\n",
    "    \n",
    "    \n",
    "\n",
    "'''\n",
    "Write df data to newly create mysql table\n",
    "'''\n",
    "def df_to_mysql(df, engine, tbl_name):\n",
    "    df.to_sql(tbl_name, engine, if_exists='replace', index_label='record', index = False)\n",
    "\n",
    "#Create the DataFrame object \n",
    "df = csv_to_df(infile)\n",
    "\n",
    "#The following line of code creates the table based on the 11.csv file. I will leave it commented.\n",
    "#create_mysql_tbl_schema(df, mysql_conn(mysql_engine()), db, db_tbl_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads 1.8 million records. Don't execute the following line as it's already been done. I promise this works :)\n",
    "#df_to_mysql(df, mysql_engine(), db_tbl_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index       1835072\n",
       "record      1835072\n",
       "age         1835072\n",
       "race        1832182\n",
       "sex         1835072\n",
       "ms          1473846\n",
       "hisp        1782570\n",
       "adjinc      1790803\n",
       "educ        1484202\n",
       "pob         1835072\n",
       "wt          1835072\n",
       "hhid        1835072\n",
       "hhnum       1835072\n",
       "reltrf      1830398\n",
       "occ          979747\n",
       "majocc       979747\n",
       "ind          979526\n",
       "majind       979526\n",
       "esr         1484169\n",
       "urban       1822030\n",
       "smsast      1822016\n",
       "inddea      1835072\n",
       "cause113    1835072\n",
       "follow      1835072\n",
       "dayod        160750\n",
       "hosp         157794\n",
       "hospd        145174\n",
       "ssnyn       1835072\n",
       "vt          1439021\n",
       "histatus    1257307\n",
       "hitype      1257307\n",
       "povpct      1835072\n",
       "stater      1835072\n",
       "rcow         981362\n",
       "tenure      1809625\n",
       "citizen      464861\n",
       "health       384129\n",
       "indalg       348759\n",
       "smok100           0\n",
       "agesmk            0\n",
       "smokstat          0\n",
       "smokhome          0\n",
       "curruse           0\n",
       "everuse           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "'''\n",
    "    This block of code is what you will need to load the 1.8 million records from the Remote MySQL database \n",
    "    via a cursor to create a DataFrame and wrangle as needed. Since the csv file we are using or any large data\n",
    "    is not feasible to be carried around in files, we connect to a remote DB for a read once operation.\n",
    "    Any operations for wrangling (trial and errors) can be done using DataFrame objects. Our instructor said a few million records \n",
    "    won't be an issue.\n",
    "    Once we are satisfied with the wrangling, we will write it to a separate table (another WORM table)\n",
    "'''\n",
    "import pandas.io.sql as psql\n",
    "\n",
    "conn = mysql_conn(mysql_engine())\n",
    "sql = \"SELECT * from \" + db_tbl_name\n",
    "new_df_from_db = df = pd.read_sql(sql, conn)\n",
    "new_df_from_db.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index       1835072\n",
       "record      1835072\n",
       "age         1835072\n",
       "race        1832182\n",
       "sex         1835072\n",
       "ms          1473846\n",
       "hisp        1782570\n",
       "adjinc      1790803\n",
       "educ        1484202\n",
       "pob         1835072\n",
       "wt          1835072\n",
       "hhid        1835072\n",
       "hhnum       1835072\n",
       "reltrf      1830398\n",
       "occ          979747\n",
       "majocc       979747\n",
       "ind          979526\n",
       "majind       979526\n",
       "esr         1484169\n",
       "urban       1822030\n",
       "smsast      1822016\n",
       "inddea      1835072\n",
       "cause113    1835072\n",
       "follow      1835072\n",
       "dayod        160750\n",
       "hosp         157794\n",
       "hospd        145174\n",
       "ssnyn       1835072\n",
       "vt          1439021\n",
       "histatus    1257307\n",
       "hitype      1257307\n",
       "povpct      1835072\n",
       "stater      1835072\n",
       "rcow         981362\n",
       "tenure      1809625\n",
       "citizen      464861\n",
       "health       384129\n",
       "indalg       348759\n",
       "smok100           0\n",
       "agesmk            0\n",
       "smokstat          0\n",
       "smokhome          0\n",
       "curruse           0\n",
       "everuse           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the good old df counts read from the CSV file to make sure the data matches the remote MySQL DB Table\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
